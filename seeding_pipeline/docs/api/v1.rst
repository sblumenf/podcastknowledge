API v1 Reference
================

This document provides a complete reference for the v1 API.

Core Functions
--------------

.. automodule:: src.api.v1.seeding
   :members: seed_podcast, seed_podcasts, get_api_version, check_api_compatibility
   :undoc-members:
   :show-inheritance:

Pipeline Class
--------------

.. autoclass:: src.api.v1.seeding.PodcastKnowledgePipeline
   :members:
   :undoc-members:
   :show-inheritance:
   :special-members: __init__

Response Schema
---------------

All v1 API functions return a dictionary with the following guaranteed fields:

.. code-block:: python

   {
       'start_time': str,              # ISO format timestamp
       'end_time': str,                # ISO format timestamp  
       'podcasts_processed': int,      # Number of podcasts processed
       'episodes_processed': int,      # Total episodes processed
       'episodes_failed': int,         # Number of failed episodes
       'processing_time_seconds': float,  # Total processing time
       'api_version': str,             # API version used ("1.0")
       # ... additional fields may be present
   }

Usage Examples
--------------

Basic Usage
~~~~~~~~~~~

.. code-block:: python

   from src.api.v1 import seed_podcast, seed_podcasts
   
   # Process a single podcast
   result = seed_podcast({
       'name': 'Tech Talk',
       'rss_url': 'https://example.com/feed.xml',
       'category': 'Technology'
   }, max_episodes=5)
   
   print(f"Processed {result['episodes_processed']} episodes")

Batch Processing
~~~~~~~~~~~~~~~~

.. code-block:: python

   # Process multiple podcasts
   podcasts = [
       {'name': 'Podcast 1', 'rss_url': 'https://...'},
       {'name': 'Podcast 2', 'rss_url': 'https://...'}
   ]
   
   result = seed_podcasts(podcasts, max_episodes_each=10)

Custom Configuration
~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   from src.core.config import Config
   
   # Create custom configuration
   config = Config()
   config.batch_size = 20
   config.checkpoint_enabled = True
   
   # Use with API
   result = seed_podcast(podcast_config, config=config)

Version Checking
~~~~~~~~~~~~~~~~

.. code-block:: python

   from src.api.v1 import get_api_version, check_api_compatibility
   
   # Get current version
   version = get_api_version()  # "1.0.0"
   
   # Check compatibility
   if check_api_compatibility("1.0"):
       print("API is compatible!")

Error Handling
--------------

The API handles errors gracefully and continues processing:

.. code-block:: python

   try:
       result = seed_podcast(podcast_config)
       
       if result['episodes_failed'] > 0:
           print(f"Warning: {result['episodes_failed']} episodes failed")
           
   except Exception as e:
       print(f"Critical error: {e}")

Deprecation Policy
------------------

The v1 API follows semantic versioning:

- **Major version (1.x.x)**: Backward compatibility guaranteed
- **Minor version (x.1.x)**: New features, backward compatible
- **Patch version (x.x.1)**: Bug fixes only

Deprecated functions will:
1. Show deprecation warnings for at least 2 minor versions
2. Continue working until the next major version
3. Provide migration guidance in warnings

Migration from v0
-----------------

If migrating from the pre-v1 API:

.. code-block:: python

   # Old way (v0)
   from src.seeding import PodcastKnowledgePipeline
   pipeline = PodcastKnowledgePipeline()
   pipeline.seed_podcast(...)
   
   # New way (v1)
   from src.api.v1 import seed_podcast
   result = seed_podcast(...)

Thread Safety
-------------

All v1 API functions are thread-safe and can be called concurrently:

.. code-block:: python

   from concurrent.futures import ThreadPoolExecutor
   from src.api.v1 import seed_podcast
   
   def process_podcast(config):
       return seed_podcast(config, max_episodes=5)
   
   with ThreadPoolExecutor(max_workers=3) as executor:
       futures = [executor.submit(process_podcast, cfg) for cfg in configs]
       results = [f.result() for f in futures]

Performance Considerations
--------------------------

- Use `max_episodes_each` parameter to limit processing
- Enable checkpoints for large podcasts
- Adjust `config.batch_size` based on available memory
- Set `use_large_context=False` for faster processing

See Also
--------

- :doc:`/configuration` - Configuration options
- :doc:`/guides/advanced_features` - Advanced usage patterns
- :doc:`/guides/troubleshooting` - Common issues and solutions