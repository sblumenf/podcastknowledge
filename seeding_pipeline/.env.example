# ==============================================================================
# SEEDING PIPELINE ENVIRONMENT CONFIGURATION
# ==============================================================================
# Production-level environment configuration for the podcast knowledge seeding pipeline
# 
# SECURITY NOTICE: This is an example file. Copy to .env and fill in your values.
# Never commit .env files containing real credentials to version control.
#
# Usage: cp .env.example .env && nano .env
# ==============================================================================

# ==============================================================================
# REQUIRED CONFIGURATION
# ==============================================================================

# Neo4j Database Configuration (REQUIRED)
# Password for your Neo4j database instance
NEO4J_PASSWORD=your_secure_neo4j_password_here

# Google/Gemini API Configuration (REQUIRED - choose one or both)
# Primary API key for Gemini LLM models - get from Google AI Studio
# Either GOOGLE_API_KEY or GEMINI_API_KEY must be set
GOOGLE_API_KEY=your_google_api_key_here
# Alternative naming convention (same key, different name)
# GEMINI_API_KEY=your_gemini_api_key_here

# ==============================================================================
# MODEL CONFIGURATION (Optional - NEW! - defaults provided)
# ==============================================================================

# Gemini model configuration for different processing tasks
# The pipeline uses different models optimized for specific tasks:
# - Flash models: Fast processing (speaker ID, conversation analysis)
# - Pro models: Complex reasoning (knowledge extraction)
# - Embedding models: Vector operations (semantic search)

# === PRODUCTION CONFIGURATION (Recommended) ===
# Optimal balance of speed and accuracy for production workloads
GEMINI_FLASH_MODEL=gemini-2.5-flash-001
GEMINI_PRO_MODEL=gemini-2.5-pro-001
GEMINI_EMBEDDING_MODEL=text-embedding-004

# === DEVELOPMENT CONFIGURATION ===
# Use faster, cheaper models for development and testing
# Uncomment these lines and comment out production config above
# GEMINI_FLASH_MODEL=gemini-2.5-flash-001
# GEMINI_PRO_MODEL=gemini-2.5-flash-001  # Use flash for everything to save costs
# GEMINI_EMBEDDING_MODEL=text-embedding-004

# === LEGACY CONFIGURATION ===
# Support for existing preview models (deprecated but still supported)
# GEMINI_FLASH_MODEL=gemini-2.5-flash-preview-05-20
# GEMINI_PRO_MODEL=gemini-2.5-pro-preview-06-05
# GEMINI_EMBEDDING_MODEL=text-embedding-004

# === LATEST MODELS ===
# Use the newest available models (may have different pricing)
# GEMINI_FLASH_MODEL=gemini-2.0-flash-001
# GEMINI_PRO_MODEL=gemini-2.5-pro-001
# GEMINI_EMBEDDING_MODEL=models/text-embedding-004

# Valid model names (validated at startup):
# Text Generation: gemini-2.0-flash-001, gemini-2.5-flash-001, gemini-2.5-pro-001
# Embeddings: text-embedding-004, models/text-embedding-004
# Legacy: gemini-2.5-flash-preview-05-20, gemini-2.5-pro-preview-06-05

# ==============================================================================
# DATABASE CONFIGURATION (Optional - defaults provided)
# ==============================================================================

# Neo4j connection URI - adjust for your deployment
NEO4J_URI=bolt://localhost:7687

# Neo4j authentication
NEO4J_USERNAME=neo4j

# Neo4j database name - use 'neo4j' for default database
NEO4J_DATABASE=neo4j

# ==============================================================================
# API KEY ROTATION (Optional - for high-volume processing)
# ==============================================================================

# Additional Gemini API keys for rotation to handle rate limits
# Useful for processing large batches of VTT files
# GEMINI_API_KEY_1=your_gemini_api_key_1_here
# GEMINI_API_KEY_2=your_gemini_api_key_2_here
# GEMINI_API_KEY_3=your_gemini_api_key_3_here
# GEMINI_API_KEY_4=your_gemini_api_key_4_here
# GEMINI_API_KEY_5=your_gemini_api_key_5_here
# GEMINI_API_KEY_6=your_gemini_api_key_6_here
# GEMINI_API_KEY_7=your_gemini_api_key_7_here
# GEMINI_API_KEY_8=your_gemini_api_key_8_here
# GEMINI_API_KEY_9=your_gemini_api_key_9_here

# Alternative LLM Services (Optional)
# OpenAI API key for GPT models (if using OpenAI instead of/alongside Gemini)
# OPENAI_API_KEY=your_openai_api_key_here

# Hugging Face token for model access (if using HF models)
# HF_TOKEN=your_hugging_face_token_here

# ==============================================================================
# FEATURE FLAGS (Optional - production defaults)
# ==============================================================================


# Enable enhanced logging with rotation and structured JSON format
# Recommended for production monitoring
# Values: true|false
ENABLE_ENHANCED_LOGGING=true

# Enable metrics collection for monitoring and performance analysis
# Recommended for production deployments
# Values: true|false
ENABLE_METRICS=true

# Enable debug mode for troubleshooting (disable in production)
# Values: true|false
DEBUG_MODE=false

# ==============================================================================
# PERFORMANCE TUNING (Optional - adjust based on your infrastructure)
# ==============================================================================

# Processing Performance
# Maximum number of concurrent files to process simultaneously
MAX_CONCURRENT_FILES=1

# Batch size for processing operations
BATCH_SIZE=10

# Maximum number of worker threads
MAX_WORKERS=4

# Memory Limits (adjust based on available system resources)
# Maximum memory usage in MB (2GB default)
MAX_MEMORY_MB=2048

# Alternative: specify in GB
# MAX_MEMORY_GB=4.0


# ==============================================================================
# LOGGING CONFIGURATION (Optional - production settings)
# ==============================================================================

# Logging level: DEBUG|INFO|WARNING|ERROR|CRITICAL
# Use INFO for production, DEBUG for troubleshooting
LOG_LEVEL=INFO

# Log format: json|text
# JSON recommended for production log aggregation
LOG_FORMAT=json

# ==============================================================================
# DIRECTORY CONFIGURATION (Optional - defaults work for most setups)
# ==============================================================================

# Directory for storing processing checkpoints
CHECKPOINT_DIR=checkpoints

# Directory for output files
OUTPUT_DIR=output

# Directory for storing API key rotation state files
STATE_DIR=data

# ==============================================================================
# PRODUCTION DEPLOYMENT NOTES
# ==============================================================================
#
# 1. SECURITY:
#    - Set restrictive file permissions: chmod 600 .env
#    - Never commit .env to version control
#    - Use secrets management in containerized deployments
#    - Rotate API keys regularly
#
# 2. MONITORING:
#    - Set ENABLE_ENHANCED_LOGGING=true
#    - Set ENABLE_METRICS=true
#    - Monitor log files in the logs/ directory
#    - Set up alerts for ERROR level logs
#
# 3. PERFORMANCE:
#    - Adjust MAX_MEMORY_MB based on available RAM
#    - Increase MAX_CONCURRENT_FILES for powerful machines
#    - Use API key rotation for high-volume processing
#    - Monitor Neo4j memory usage and tune accordingly
#
# 4. SCALABILITY:
#    - Consider using multiple Gemini API keys for rate limit handling
#    - Adjust batch sizes based on VTT file sizes
#    - Monitor checkpoint directory for disk usage
#
# 5. BACKUP:
#    - Backup Neo4j database regularly
#    - Backup checkpoint directory for recovery
#    - Keep processed VTT files for reprocessing if needed
#
# ==============================================================================