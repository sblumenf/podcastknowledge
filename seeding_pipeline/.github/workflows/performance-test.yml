name: Performance Tests

on:
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'

jobs:
  performance-test:
    name: Run Performance Tests
    runs-on: ubuntu-latest
    services:
      neo4j:
        image: neo4j:5.12.0
        env:
          NEO4J_AUTH: neo4j/testpassword
          NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
          NEO4J_dbms_memory_heap_max__size: 2G
          NEO4J_dbms_memory_pagecache_size: 1G
        ports:
          - 7474:7474
          - 7687:7687
        options: >-
          --health-cmd "neo4j status"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for comparisons
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-perf-${{ hashFiles('requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-perf-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -e .
    
    - name: Download test data
      run: |
        # Download sample podcast data for testing
        mkdir -p test_data
        curl -L https://example.com/test-podcast.mp3 -o test_data/test-podcast.mp3 || echo "Using mock data"
    
    - name: Run performance benchmarks
      env:
        NEO4J_URI: bolt://localhost:7687
        NEO4J_USER: neo4j
        NEO4J_PASSWORD: testpassword
        REDIS_URL: redis://localhost:6379/0
      run: |
        python -m pytest tests/performance/ -v \
          --benchmark-only \
          --benchmark-json=benchmark_results.json \
          --benchmark-save=current \
          --benchmark-max-time=300
    
    - name: Store benchmark result
      uses: benchmark-action/github-action-benchmark@v1
      with:
        name: Python Benchmark
        tool: 'pytest'
        output-file-path: benchmark_results.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true
        alert-threshold: '150%'
        comment-on-alert: true
        fail-on-alert: true
        alert-comment-cc-users: '@maintainers'
    
    - name: Memory profiling
      run: |
        # Run memory profiling
        python -m memory_profiler tests/performance/memory_test.py > memory_profile.txt
    
    - name: Upload performance artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-results
        path: |
          benchmark_results.json
          memory_profile.txt
          .benchmarks/
    
    - name: Comment on PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('benchmark_results.json', 'utf8'));
          
          let comment = '## ðŸ“Š Performance Test Results\n\n';
          comment += '| Test | Duration | Memory Peak | Status |\n';
          comment += '|------|----------|-------------|--------|\n';
          
          results.benchmarks.forEach(bench => {
            const duration = bench.stats.mean.toFixed(3);
            const memory = (bench.extra_info.memory_peak_mb || 'N/A');
            const status = bench.stats.mean < 10 ? 'âœ…' : 'âš ï¸';
            comment += `| ${bench.name} | ${duration}s | ${memory} MB | ${status} |\n`;
          });
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  load-test:
    name: Load Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up K6
      run: |
        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
    
    - name: Run load tests
      run: |
        # Run K6 load tests if API endpoints are available
        # k6 run tests/load/api_load_test.js || echo "Load tests not configured"
        echo "Load tests would run here"
    
    - name: Generate load test report
      run: |
        echo "# Load Test Report" > load_test_report.md
        echo "Generated at: $(date)" >> load_test_report.md
        echo "Load testing not yet configured" >> load_test_report.md
    
    - name: Upload load test results
      uses: actions/upload-artifact@v3
      with:
        name: load-test-results
        path: load_test_report.md